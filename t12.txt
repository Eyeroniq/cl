Theory of DEAP and Evolutionary Algorithms
DEAP (Distributed Evolutionary Algorithms in Python) is a flexible framework for rapidly prototyping and running evolutionary computation experiments. At its core, it embodies the paradigm of genetic algorithms (GAs)—a population‑based search inspired by natural selection. Each candidate solution (an “individual”) is encoded as a genome (here, a list of floats). A fitness function evaluates how well each individual solves the problem (in our example, minimizing the sum of squares of its components). Over successive generations, individuals are selected based on fitness, recombined (crossover), and mutated to explore the search space. DEAP provides ready‑made building blocks—creator classes for fitness and individuals, a toolbox to register genetic operators, and algorithms for orchestrating the evolutionary loop—so you can focus on problem‑specific details like genome representation and evaluation.

How the DEAP Implementation Works (Step by Step)

Define Fitness and Individual Classes

Using creator.create, we make a FitnessMin class (to minimize our objective) and an Individual class (a Python list tagged with that fitness).

Set Up the Toolbox:

Register a random attribute generator (attr_float) that produces uniform floats in 
−5,5

Define how to build an Individual by repeating that attribute generator three times.

Define how to build a Population as a list of such individuals.

Register Genetic Operators:

Evaluation: eval_func computes the sum of squares of an individual’s genes, returning a tuple as required by DEAP.

Crossover: cxBlend mixes pairs of parents gene‑wise with a blend factor α=0.5.

Mutation: mutGaussian perturbs genes by adding Gaussian noise (μ=0, σ=1) with a 20% chance per gene.

Selection: selTournament picks the best individuals out of random groups of size 3.

Initialize Population:

Create 50 individuals with random weights via toolbox.population(n=50).

Evolution Loop (20 Generations):

Variation: algorithms.varAnd applies crossover (50% chance per pair) and mutation (10% chance per individual) to produce offspring.

Evaluation: Compute fitness for each offspring by mapping toolbox.evaluate and storing ind.fitness.values.

Selection: Choose the next generation by running toolbox.select on the offspring, maintaining population size.

Result Extraction:

After the final generation, use tools.selBest to retrieve the individual with the lowest sum of squares and print its genome and fitness.

This pipeline demonstrates the standard GA cycle—evaluate → select → reproduce → replace—automated by DEAP’s modular design so you can swap in different representations, operators, or selection strategies with minimal code changes.